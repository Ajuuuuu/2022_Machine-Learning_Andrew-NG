{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Optional Lab - Simple Neural Network\n",
    "In this lab, we will build a small neural network using Numpy. It will be the same \"coffee roasting\" network you implemented in Tensorflow.\n",
    "   <center> <img  src=\"./images/C2_W1_CoffeeRoasting.png\" width=\"400\" />   <center/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the 'package' argument is required to perform a relative import for './deeplearning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./deeplearning.mplstyle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlab_utils_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dlc, sigmoid\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\site-packages\\matplotlib\\style\\core.py:153\u001b[0m, in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    151\u001b[0m pkg, _, name \u001b[38;5;241m=\u001b[39m style\u001b[38;5;241m.\u001b[39mrpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     path \u001b[38;5;241m=\u001b[39m (\u001b[43mimportlib_resources\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m             \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSTYLE_EXTENSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    155\u001b[0m     style \u001b[38;5;241m=\u001b[39m _rc_params_in_file(path)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mIOError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# There is an ambiguity whether a dotted name refers to a\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# package.style_name or to a dotted file path.  Currently,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# either use Path objects or be prepended with \"./\" and use\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# the slash as marker for file paths.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\importlib\\_common.py:22\u001b[0m, in \u001b[0;36mfiles\u001b[1;34m(package)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfiles\u001b[39m(package):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# type: (Package) -> Traversable\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    Get a Traversable resource from a package\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m from_package(\u001b[43mget_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\importlib\\_common.py:66\u001b[0m, in \u001b[0;36mget_package\u001b[1;34m(package)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_package\u001b[39m(package):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# type: (Package) -> types.ModuleType\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124;03m\"\"\"Take a package name or module object and return the module.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    Raise an exception if the resolved module is not a package.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     resolved \u001b[38;5;241m=\u001b[39m \u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_spec(resolved)\u001b[38;5;241m.\u001b[39msubmodule_search_locations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a package\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\importlib\\_common.py:57\u001b[0m, in \u001b[0;36mresolve\u001b[1;34m(cand)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresolve\u001b[39m(cand):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# type: (Package) -> types.ModuleType\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cand \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cand, types\u001b[38;5;241m.\u001b[39mModuleType) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\importlib\\__init__.py:121\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m package:\n\u001b[0;32m    119\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpackage\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument is required to perform a relative \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport for \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m character \u001b[38;5;129;01min\u001b[39;00m name:\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m character \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: the 'package' argument is required to perform a relative import for './deeplearning'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "import tensorflow as tf\n",
    "from lab_utils_common import dlc, sigmoid\n",
    "from lab_coffee_utils import load_coffee_data, plt_roast, plt_prob, plt_layer, plt_network, plt_output_unit\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet\n",
    "This is the same data set as the previous lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = load_coffee_data();\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the coffee roasting data below. The two features are Temperature in Celsius and Duration in minutes. [Coffee Roasting at Home](https://www.merchantsofgreencoffee.com/how-to-roast-green-coffee-in-your-oven/) suggests that the duration is best kept between 12 and 15 minutes while the temp should be between 175 and 260 degrees Celsius. Of course, as the temperature rises, the duration should shrink. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt_roast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt_roast\u001b[49m(X,Y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt_roast' is not defined"
     ]
    }
   ],
   "source": [
    "plt_roast(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data\n",
    "To match the previous lab, we'll normalize the data. Refer to that lab for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Temperature Max, Min pre normalization: {np.max(X[:,0]):0.2f}, {np.min(X[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min pre normalization: {np.max(X[:,1]):0.2f}, {np.min(X[:,1]):0.2f}\")\n",
    "norm_l = tf.keras.layers.Normalization(axis=-1)\n",
    "norm_l.adapt(X)  # learns mean, variance\n",
    "Xn = norm_l(X)\n",
    "print(f\"Temperature Max, Min post normalization: {np.max(Xn[:,0]):0.2f}, {np.min(Xn[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min post normalization: {np.max(Xn[:,1]):0.2f}, {np.min(Xn[:,1]):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Model (Forward Prop in NumPy)\n",
    "<center> <img  src=\"./images/C2_W1_RoastingNetwork.PNG\" width=\"200\" />   <center/>  \n",
    "Let's build the \"Coffee Roasting Network\" described in lecture. There are two layers with sigmoid activations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "As described in lecture, it is possible to build your own dense layer using NumPy. This can then be utilized to build a multi-layer neural network. \n",
    "\n",
    "<img src=\"images/C2_W1_dense2.PNG\" width=\"600\" height=\"450\">\n",
    "\n",
    "In the first optional lab, you constructed a neuron in NumPy and in Tensorflow and noted their similarity. A layer simply contains multiple neurons/units. As described in lecture, one can utilize a for loop to visit each unit (`j`) in the layer and perform the dot product of the weights for that unit (`W[:,j]`) and sum the bias for the unit (`b[j]`) to form `z`. An activation function `g(z)` can then be applied to that result. Let's try that below to build a \"dense layer\" subroutine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_dense(a_in, W, b, g):\n",
    "    \"\"\"\n",
    "    Computes dense layer\n",
    "    Args:\n",
    "      a_in (ndarray (n, )) : Data, 1 example \n",
    "      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units\n",
    "      b    (ndarray (j, )) : bias vector, j units  \n",
    "      g    activation function (e.g. sigmoid, relu..)\n",
    "    Returns\n",
    "      a_out (ndarray (j,))  : j units|\n",
    "    \"\"\"\n",
    "    units = W.shape[1]\n",
    "    a_out = np.zeros(units)\n",
    "    for j in range(units):               \n",
    "        w = W[:,j]                                    \n",
    "        z = np.dot(w, a_in) + b[j]         \n",
    "        a_out[j] = g(z)               \n",
    "    return(a_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell builds a two-layer neural network utilizing the `my_dense` subroutine above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sequential(x, W1, b1, W2, b2):\n",
    "    a1 = my_dense(x,  W1, b1, sigmoid)\n",
    "    a2 = my_dense(a1, W2, b2, sigmoid)\n",
    "    return(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can copy trained weights and biases from the previous lab in Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_tmp = np.array( [[-8.93,  0.29, 12.9 ], [-0.1,  -7.32, 10.81]] )\n",
    "b1_tmp = np.array( [-9.82, -9.28,  0.96] )\n",
    "W2_tmp = np.array( [[-31.18], [-27.59], [-32.56]] )\n",
    "b2_tmp = np.array( [15.41] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "<img align=\"left\" src=\"./images/C2_W1_RoastingDecision.PNG\"     style=\" width:380px; padding: 10px 20px; \" >\n",
    "\n",
    "Once you have a trained model, you can then use it to make predictions. Recall that the output of our model is a probability. In this case, the probability of a good roast. To make a decision, one must apply the probability to a threshold. In this case, we will use 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by writing a routine similar to Tensorflow's `model.predict()`. This will take a matrix $X$ with all $m$ examples in the rows and make a prediction by running the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(X, W1, b1, W2, b2):\n",
    "    m = X.shape[0]\n",
    "    p = np.zeros((m,1))\n",
    "    for i in range(m):\n",
    "        p[i,0] = my_sequential(X[i], W1, b1, W2, b2)\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try this routine on two examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst = np.array([\n",
    "    [200,13.9],  # postive example\n",
    "    [200,17]])   # negative example\n",
    "X_tstn = norm_l(X_tst)  # remember to normalize\n",
    "predictions = my_predict(X_tstn, W1_tmp, b1_tmp, W2_tmp, b2_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the probabilities to a decision, we apply a threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.zeros_like(predictions)\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >= 0.5:\n",
    "        yhat[i] = 1\n",
    "    else:\n",
    "        yhat[i] = 0\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be accomplished more succinctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = (predictions >= 0.5).astype(int)\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the operation of the whole network and is identical to the Tensorflow result from the previous lab.\n",
    "The left graph is the raw output of the final layer represented by the blue shading. This is overlaid on the training data represented by the X's and O's.   \n",
    "The right graph is the output of the network after a decision threshold. The X's and O's here correspond to decisions made by the network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "netf= lambda x : my_predict(norm_l(x),W1_tmp, b1_tmp, W2_tmp, b2_tmp)\n",
    "plt_network(X,Y,netf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "You have built a small neural network in NumPy. \n",
    "Hopefully this lab revealed the fairly simple and familiar functions which make up a layer in a neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
