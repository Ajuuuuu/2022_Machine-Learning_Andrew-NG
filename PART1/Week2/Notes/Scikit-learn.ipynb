{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e71410b5",
   "metadata": {},
   "source": [
    "## Learn Scikit-learn with Optional Labs and ChatGPT4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560af13f",
   "metadata": {},
   "source": [
    "## 1. sklearn.linear_model.SGDRegressor\n",
    "    sklearn.linear_model.SGDRegressor 是 scikit-learn（一个流行的 Python 机器学习库）中的一个类，用于实现随机梯度下降（Stochastic Gradient Descent，简称 SGD）线性回归。\n",
    "    \n",
    "    在 scikit-learn 中，SGDRegressor 类提供了一个易于使用的接口，让您可以方便地训练线性回归模型\n",
    "    \n",
    "    使用时，先创建一个SGDRegressor对象\n",
    "    \n",
    "### SGDRegressor 一些主要的参数有：\n",
    "        loss (指定损失函数) : str, default=’squared_error’\n",
    "        \n",
    "        penalty (指定正则化项) : {‘l2’, ‘l1’, ‘elasticnet’, None}, default=’l2’\n",
    "        \n",
    "        alpha (正则化系数): float default=0.0001\n",
    "        \n",
    "        max_iter (最大迭代次数): int, default=1000\n",
    "        \n",
    "        tol (收敛阈值): float or None, default=1e-3\n",
    "            如果在连续两次迭代之间的损失之差小于该值，则认为模型已收敛，停止训练。\n",
    "            \n",
    "        learning_rate (学习率): str, default=’invscaling’\n",
    "            'constant': 固定学习率。\n",
    "            'optimal': 根据一个特定的公式自动调整学习率，该公式与迭代次数有关。\n",
    "            'invscaling': 随着迭代次数的增加，学习率逐渐减小，按照 eta0 / pow(t, power_t) 进行调整，其中 t 是迭代次数。\n",
    "            'adaptive': 如果损失没有显著下降，学习率将减小。 \n",
    "        \n",
    "        eta0 (初始学习率): float, default=0.01\n",
    "        \n",
    "        power_t : float, default=0.25\n",
    "            用于调整学习率的指数。较小的值导致学习率更快地减小。\n",
    "            \n",
    "### fit方法\n",
    "    在 scikit-learn 中，fit 方法是一个通用的方法，用于训练（拟合）机器学习模型。对于 SGDRegressor，fit 方法将使用随机梯度下降（SGD）算法在给定的训练数据（X_train 和 y_train）上训练线性回归模型。\n",
    "      \n",
    "    通过SGDRegressor对象可以调用fit()方法，同时通过此方法训练完成之后，模型也将存储在该对象中，通过 coef_ 和 intercept_ 属性可以分别查看该模型得出的权重与偏执的值\n",
    "    同时也可以通过 predict 方法，放入新的x的值，来得到通过本模型预测的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a1211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此单元内的代码属于例子，无法真正运行\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# 通过SGDRegressor创建了一个 SGDRegressor对象 叫sgd_1\n",
    "sgd_1 = SGDRegressor(max_iter=200, eta0=0.01, learning_rate='invscaling', tol=0.001)\n",
    "# 获得权重与偏执\n",
    "w = sgd_1.coef_\n",
    "b = sgd_1.intercept_\n",
    "# 通过 predict 去预测\n",
    "y_hat = sgd_1.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dfd252",
   "metadata": {},
   "source": [
    "## 2. sklearn.preprocessing.StandardScaler\n",
    "    StandardScaler 是 scikit-learn 中的一个类，用于对数据进行特征缩放。特征缩放是预处理步骤的一部分，可以提高某些机器学习算法（特别是基于梯度的算法，如梯度下降）的性能和收敛速度。\n",
    "    \n",
    "    使用时，首先需要创造一个StandardScaler对象\n",
    "    \n",
    "### fit_transform(X_train)\n",
    "    scaler.fit_transform(X_train) 首先根据 X_train 计算均值和标准差，然后使用这些统计量将 X_train 标准化。这相当于分别调用 scaler.fit(X_train) 和 scaler.transform(X_train)。\n",
    "    \n",
    "    在许多情况下，使用 fit_transform 方法可以提高代码的简洁性。需要注意的是，fit_transform 仅应用于训练数据，而对于测试数据，仍需要使用 transform 方法进行转换。这是因为在预处理时，测试数据应使用与训练数据相同的统计量进行转换，以确保训练和测试数据具有相似的分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fbf95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此单元内的代码属于例子，无法真正运行\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee2a71b",
   "metadata": {},
   "source": [
    "## 3. 下面写一个实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53383541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109.62028122 -20.86817892 -32.10249594 -38.06051334]\n",
      "[363.15486334]\n",
      "predict:  [294.08403505 486.65025414 388.45368771 492.26776009]\n",
      "correct:  [300.  509.8 394.  540. ]\n"
     ]
    }
   ],
   "source": [
    "# 导包\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 导入训练数据\n",
    "X_train = np.loadtxt('./x_train.txt')\n",
    "Y_train = np.loadtxt('./y_train.txt')\n",
    "\n",
    "# 特征缩放\n",
    "scaler = StandardScaler()\n",
    "X_train_scalered = scaler.fit_transform(X_train)\n",
    "\n",
    "# 创建随机梯度下降模型\n",
    "SGDR = SGDRegressor(max_iter=5000, eta0=0.001)\n",
    "SGDR.fit(X_train_scalered, Y_train)\n",
    "\n",
    "# 输出训练后得到的模型参数\n",
    "w_finnal = SGDR.coef_\n",
    "b_finnal = SGDR.intercept_\n",
    "print(w_finnal)\n",
    "print(b_finnal)\n",
    "\n",
    "# 比较数据之间的差距\n",
    "Y_predict = SGDR.predict(X_train_scalered[:4])\n",
    "print(\"predict: \" ,Y_predict)\n",
    "print(\"correct: \" ,Y_train[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f1fc93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
