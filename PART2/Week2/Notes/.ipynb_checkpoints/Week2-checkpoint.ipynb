{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37dcea98",
   "metadata": {},
   "source": [
    "## 1.1 TensorFlow implementation Tensorflow实现\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1b3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=25, activation='sigmoid', name = 'layer_1'),\n",
    "    Dense(units=15, activation='sigmoid', name = 'layer_2'),\n",
    "    Dense(units=1, activation='sigmoid', name = 'layer_3'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231f5962",
   "metadata": {},
   "source": [
    "接下来模型会调用complie方法，它会将各个参数配置好，并准备好进行训练。\n",
    "常见参数包括：\n",
    "\n",
    "optimizer：优化器，如Adam、SGD等。\n",
    "\n",
    "loss：损失函数，如均方误差（mse）、交叉熵（categorical_crossentropy）等。\n",
    "\n",
    "metrics：评估指标，如准确率（accuracy）、精确率（precision）等。\n",
    "\n",
    "loss_weights：各损失函数的权重。\n",
    "\n",
    "sample_weight_mode：样本权重的计算方式。\n",
    "\n",
    "weighted_metrics：带权重的评估指标。\n",
    "\n",
    "target_tensors：目标张量。\n",
    "\n",
    "**kwargs：其他参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac5b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eb164f",
   "metadata": {},
   "source": [
    "二元交叉熵BinaryCrossentropy是一种常用的损失函数，用于二分类问题中，它是交叉熵（Cross-entropy）的一种特殊形式。对于二分类问题，每个样本只有两种可能的标签值，通常用0表示一个类别，用1表示另一个类别。BinaryCrossentropy的计算公式如下：\n",
    "\n",
    "BinaryCrossentropy=−(ylog(p)+(1−y)log(1−p))\n",
    "\n",
    "其中，y 表示真实标签的值，p 表示预测的标签概率值。\n",
    "p可以通过 sigmoid 函数得到\n",
    "\n",
    "注意：这里只是一个求损失的函数 与 sigmoid函数不要混淆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727af5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = BinaryCrossentropy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905e1d4",
   "metadata": {},
   "source": [
    "## 1.2 Training Details 训练细节\n",
    "    这里区分以下Loss Function损失函数 和Cost Function代价函数\n",
    "    损失函数是指针对单个样本计算的误差，代价函数则是针对所有样本计算的误差的平均值\n",
    "    \n",
    "![img1](./img/01.png)\n",
    "    \n",
    "    \n",
    "    \n",
    "Keras最初是由Francois Chollet开发的一个高级深度学习框架，旨在为开发者提供简单易用的API，快速搭建深度学习模型。最初Keras是基于Theano库实现的，但是随着TensorFlow的流行，Keras也提供了基于TensorFlow的后端实现。\n",
    "\n",
    "    Backpropagation（反向传播）是一种用于训练神经网络的算法:\n",
    "在训练神经网络时，我们通过前向传播计算出网络的输出结果，并将其与真实标签进行比较，得到一个误差值。然后，通过反向传播算法，将误差从输出层向输入层反向传播，计算每个权重和偏置对误差的贡献，最终通过梯度下降算法更新每个权重和偏置的值，使得网络的输出与实际输出之间的误差最小化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716521ab",
   "metadata": {},
   "source": [
    "## 2.1 Alternatives to the sigmoid activation sigmoid激活函数的替代方案\n",
    "    \n",
    "ReLU（Rectified Linear Unit）是一种常用的激活函数，它将所有小于0的输入值置为0，而大于等于0的输入值不做任何处理。具体来说，ReLU的数学表达式为：\n",
    "\n",
    "$$ f(x)=max(0,x) $$\n",
    "\n",
    "对于实际的情况，常用三种激活函数：\n",
    "$$  f(z) = \\frac{1}{1 + e^{-z}}  $$\n",
    "$$  f(z)=max(0,z) $$\n",
    "$$ f(z)=z$$\n",
    "\n",
    "注意这里用的z而并非x，第一个函数为sigmoid函数，第二个是ReLU激活函数，第三是线性激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acce895",
   "metadata": {},
   "source": [
    "## 2.2 Choosing activation functions 如何选择激活函数\n",
    "    \n",
    "**Output Layer** (根据你希望得到的y的值来选择激活函数):\n",
    "![img2](./img/02.png)\n",
    "\n",
    "**Hidden Layers:**\n",
    "    The ReLU function is the most common choice in Hidden Layers\n",
    "    \n",
    "**在隐藏层中，我们更倾向于选择ReLU作为激活函数，而不是sigmoid的原因？（以下解答来自chatGPT）**\n",
    "   \n",
    "    在隐藏层中，选择ReLU作为激活函数而不是sigmoid的主要原因是，ReLU具有比sigmoid更好的优化性能，能够加速深度神经网络的训练。\n",
    "\n",
    "    具体来说，当使用sigmoid作为激活函数时，由于其S型曲线，当输入比较大或比较小时，激活函数的导数非常接近于0，导致反向传播过程中的梯度消失问题，使得深度神经网络很难进行有效的训练。而ReLU的导数在正数区间上始终为1，这就避免了梯度消失的问题，并且可以有效地缓解梯度爆炸的问题。\n",
    "\n",
    "    此外，ReLU还具有计算速度快、实现简单等优点。ReLU的计算只需要比较输入是否大于0即可，而sigmoid则需要进行指数运算，计算量较大。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c439d161",
   "metadata": {},
   "source": [
    "## 2.3 Why do we need activation functions? 我们为何需要激活函数\n",
    "    多层神经网络不能在所有层里都使用线性激活函数来作为激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18cfbc0",
   "metadata": {},
   "source": [
    "## 3.1 Multiclass 多分类\n",
    "target y can take more than two possible values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025078e3",
   "metadata": {},
   "source": [
    "## 3.2 Softmax \n",
    "是逻辑回归的泛化\n",
    "![img3](./img/03.png)\n",
    "![img4](./img/04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed1c201",
   "metadata": {},
   "source": [
    "## 3.3 Neural Network with Softmax output 神经网络的Softmax输出\n",
    "![img5](./img/05.png)\n",
    "\n",
    "    注意：z和最后输出的a是不一样的，根据不同的激活函数将z带入得到不同的a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a70893a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于上诉例子\n",
    "# 对于对十个分类的例子，输出层需要有10个神经元\n",
    "model = Sequential([\n",
    "    Dense(units=25, activation='relu', name = 'layer_1'),\n",
    "    Dense(units=15, activation='relu', name = 'layer_2'),\n",
    "    Dense(units=10, activation='softmax', name = 'layer_3'),\n",
    "])\n",
    "\n",
    "# 代价函数\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "model.compilei(loss = SparseCategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f31aa2",
   "metadata": {},
   "source": [
    "## 3.4 Improved implementation of softmax Softmax的改进实现\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aba84b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1= 0.000200000000000000\n",
      "x2= 0.000199999999999978\n"
     ]
    }
   ],
   "source": [
    "x1 = 2.0/ 10000\n",
    "x2 = 1 + (1 / 10000) - (1 - 1 / 10000)\n",
    "print(f\"x1={x1: .18f}\")\n",
    "print(f\"x2={x2: .18f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c7421",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=25, activation='sigmoid', name = 'layer_1'),\n",
    "    Dense(units=15, activation='sigmoid', name = 'layer_2'),\n",
    "    Dense(units=1, activation='sigmoid', name = 'layer_3'),\n",
    "])\n",
    "model.compile(loss = BinaryCrossentropy())\n",
    "\n",
    "# ------------------------------------------------ #\n",
    "\n",
    "#对于上述的代码 为了减小误差 我们做出以下改变\n",
    "model = Sequential([\n",
    "    Dense(units=25, activation='sigmoid', name = 'layer_1'),\n",
    "    Dense(units=15, activation='sigmoid', name = 'layer_2'),\n",
    "    Dense(units=1, activation='linear', name = 'layer_3'),\n",
    "])\n",
    "model.compile(loss = BinaryCrossentropy(from_logits = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c325b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于Softmax 我们做以下的改进\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=25, activation='relu', name = 'layer_1'),\n",
    "    Dense(units=15, activation='relu', name = 'layer_2'),\n",
    "    Dense(units=10, activation='linear', name = 'layer_3'),\n",
    "])\n",
    "\n",
    "# 代价函数\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "model.compilei(loss = SparseCategoricalCrossentropy(from_logits = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea49caf",
   "metadata": {},
   "source": [
    "所以我们改进后得到的代码，输出层输出的并非是最后的概率，而是z\n",
    "对于预测值，我们要想得到正确的结果，就必须将z再次带入Logistic函数中计算得到概率，这是需要注意的地方"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4714d12b",
   "metadata": {},
   "source": [
    "## 3.5 Classification with multiple outputs 多标签分类\n",
    "optional\n",
    "\n",
    "![img6](./img/06.png)\n",
    "\n",
    "    注意：注意区分多分类问题与多标签分类\n",
    "**多分类和多标签分类是两种不同的分类问题。**\n",
    "\n",
    "**多分类问题是指将一个样本分为多个不同的类别中的一类。在这种情况下，每个样本只能属于一个类别。常见的多分类问题包括图像分类、文本分类、手写数字识别等。**\n",
    "\n",
    "**而多标签分类问题是指将一个样本分为多个可能属于的类别。在这种情况下，每个样本可以同时属于多个类别。常见的多标签分类问题包括标签预测、图像标注等。**\n",
    "    \n",
    "\n",
    "    也可以表述为，多分类问题得到的结果的概率相加为1，而多标签分类问题不一定等于1，也可以大于1，小于1\n",
    "\n",
    "![img7](./img/07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a6303",
   "metadata": {},
   "source": [
    "## 4.1 Advanced Optimization 高级优化方法\n",
    "It's algorithm which is much faster than GD\n",
    "For GD, we always have to adjust the learning rate\n",
    "\n",
    "    Adam\n",
    "![img8](./img/08.png)  \n",
    "\n",
    "Adam（Adaptive Moment Estimation）是一种常用的梯度优化算法，它结合了动量梯度下降和自适应学习率的优点，能够高效地更新神经网络的参数。\n",
    "\n",
    "Adam算法的优点在于它对于不同的参数能够自适应地调整学习率，并且能够有效地防止梯度消失和爆炸问题。在深度学习中，Adam算法常常被用于训练神经网络。\n",
    "\n",
    "(上述介绍来自chatGPT4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "224ba226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于代码的改进\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=25, activation='relu', name = 'layer_1'),\n",
    "    Dense(units=15, activation='relu', name = 'layer_2'),\n",
    "    Dense(units=10, activation='linear', name = 'layer_3'),\n",
    "])\n",
    "model.compile(optimizer = Adam(learning_rate = 1e-3),\n",
    "    loss = SparseCategoricalCrossentropy(from_logits = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb32598",
   "metadata": {},
   "source": [
    "## 4.2 Additional Layer Types 其他网络层类型\n",
    "\n",
    "CNN(卷积神经网络 convolutional neural network):\n",
    "    Each Neuron only looks at part of the previous layer's inputs\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6334d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
